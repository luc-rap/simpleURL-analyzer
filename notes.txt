lexikalny analyzator MOZE byt pomocou kniznice na konecny automat

syntakticky analyzator NESMIE byt pomocou kniznice (mozu sa pouzivat len datove struktury, ziadne automaty atd)

cize to co sme robili na cviku manualne pomocou stacku a tabulky bola syntakticka analyza, to co sme brali 
ako vstup uz boli tokeny, musite si tento proces implementovat samy, 
jedine co na to potrebujete je stack a nejaka datova struktura, ktora reprezentuje tabulku

kniznica - iba lexikalny analyzator
syntakticka - stack, ds na reprezentaciu prekladovej tabulky (ziadne pda a tak dalej)
(a tato sprava je correct)
nasekat na tokeny -> ide do syntaktickeho 
(zjednodusene - v juekorych sa da ze je to rozbite az na jednotlive pismenka, 
lexikalny analyzator by to mohol prehlasit za name. lex musi prejst cez ten string co zadava, 
a musi z toho tokeny. syntakticky po lexikalnom, cista pajpa)

lexikalny - string - co su tokeny - syntax- token token zero na vrchu zasobnika toto (literally co je to na cvikach). 
tokeny sa standradne robi cez regex, ale teraz treba konecny automat a citat znak po znaku a prehlasovat za tokeny. 
ideally konecnym automatom

kazde pismenko je token
http cele prehlasi za token

tokeny = terminaly, spracovane lexikalnym analyzatorom

token A...z tak kazde pismenko je token, tak nech lex cita a prehlasi za token. ked najde http:// tak prehlasi za token
vsetko co hore  v tabulke prechodov tak su tokeny

